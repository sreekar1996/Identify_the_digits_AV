{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/train/0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/train/1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/train/2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/train/3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/train/4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename  label\n",
       "0  Images/train/0.png      4\n",
       "1  Images/train/1.png      9\n",
       "2  Images/train/2.png      1\n",
       "3  Images/train/3.png      7\n",
       "4  Images/train/4.png      3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator ,load_img\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"filename\"]=data[\"filename\"].apply(lambda x : \"Images/train/\"+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "size=28,28\n",
    "d=[]\n",
    "#from PIL import Image\n",
    "import numpy\n",
    "for i in data[\"filename\"]:\n",
    "    im = cv2.imread(i)\n",
    "    im= cv2.resize(im,size)\n",
    "    np_i = numpy.array(im)\n",
    "    np_i=np_i/255\n",
    "    d.append(np_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical \n",
    "labels = to_categorical(labels,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a2ed60630>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAL8ElEQVR4nO3db6hUdR7H8c9nyxCqB7aRuOVqWz5o6YGJyUJhLVGkRBrRkg8WN4obUUtRxEYL1cNYTB9FdfvrLm0S9M8HtpuIFD5Iuoqbmpht3DVz8CI9KCFqte8+uMflZnfOHWfOmTP6fb9gmJnzmzPny3A/93fO+Z2ZnyNCAE5/P2u6AAD9QdiBJAg7kARhB5Ig7EASZ/ZzY7Y59Q/ULCI82fKeenbbN9rea/sz24/08l4A6uVux9ltnyHpU0nXSzog6SNJKyLik5J16NmBmtXRsy+S9FlEfB4R30taJ2lZD+8HoEa9hP1CSV9MeH6gWPYjtodsj9ge6WFbAHrUywm6yXYVfrKbHhHDkoYlduOBJvXSsx+QNHvC84skHeytHAB16SXsH0maZ/ti22dJul3S+mrKAlC1rnfjI+Ko7fsk/VPSGZJeiojdlVUGoFJdD711tTGO2YHa1XJRDYBTB2EHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgia7nZ5ck26OSvpF0TNLRiFhYRVEAqtdT2Au/jYjDFbwPgBqxGw8k0WvYQ9J7trfZHprsBbaHbI/YHulxWwB64IjofmX7FxFx0PYFkjZK+mNEfFDy+u43BqAjEeHJlvfUs0fEweJ+TNJbkhb18n4A6tN12G2fbfvc448l3SBpV1WFAahWL2fjZ0p6y/bx9/l7RPyjkqoAVK6nY/aT3hjH7EDtajlmB3DqIOxAEoQdSIKwA0kQdiCJKr4Ik8LVV1/dtm3lypWl6951111Vl/MjrVarbdvq1atL13366adL27/99tuuasLgoWcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgST41lvhmmuuKW1/9tln27aNjJT/4tYLL7zQVU2dWrBgQdu2xYsXl6572WWXlbbfc889pe2bN28ubUf/8a03IDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfbCunXrStvffffdtm1r166tupzKTJ8+vbT95ZdfLm2/+eabS9ufe+650vaHH364bduxY8dK10V3GGcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSQYZy9M9X32Dz/8sG3bd999V3U5fXPmmeVTB9x6662l7VON069atapt22OPPVa6LrrT9Ti77Zdsj9neNWHZebY32t5X3M+oslgA1etkN/4VSTeesOwRSZsiYp6kTcVzAANsyrBHxAeSvjph8TJJx68RXStpecV1AahYt3O9zYyIliRFRMv2Be1eaHtI0lCX2wFQkdondoyIYUnD0mCfoANOd90OvR2yPUuSivux6koCUIduw75e0vF5ildKeqeacgDUZcpxdtuvSbpW0vmSDkl6XNLbkl6X9EtJ+yXdFhEnnsSb7L3YjT/NLFmypLT97bffbts2d+7c0nXL5p1He+3G2ac8Zo+IFW2aruupIgB9xeWyQBKEHUiCsANJEHYgCcIOJMFXXFGr4eHhtm3Tpk0rXfeOO+6oupwU+ClpIDnCDiRB2IEkCDuQBGEHkiDsQBKEHUii9l+qQW4bNmxo2/bggw/2sRLQswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzozFXXnllaftUPzU9OjpaXTEJ0LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6NWhw8fbts2ffr00nXnzJlT2s44+8mZsme3/ZLtMdu7Jix7wvaXtncUt6X1lgmgV53sxr8i6cZJlq+JiPnFrf3PkQAYCFOGPSI+kPRVH2oBUKNeTtDdZ/vjYjd/RrsX2R6yPWJ7pIdtAehRt2F/RtIlkuZLakl6qt0LI2I4IhZGxMIutwWgAl2FPSIORcSxiPhB0vOSFlVbFoCqdRV227MmPL1F0q52rwUwGKYcZ7f9mqRrJZ1v+4CkxyVda3u+pJA0KunuGmvEKWzLli1t21qtVh8rwZRhj4gVkyx+sYZaANSIy2WBJAg7kARhB5Ig7EAShB1Igq+4ojHbtm0rbV++fHlp+/vvv19lOac9enYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJxdjTmpptuKm1fs2ZNnyrJgZ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnB0Da+/evU2XcFqhZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnR60uv/zytm1Hjx4tXXfr1q1Vl5PalD277dm2N9veY3u37fuL5efZ3mh7X3E/o/5yAXSrk934o5IeiojLJP1G0r22fy3pEUmbImKepE3FcwADasqwR0QrIrYXj7+RtEfShZKWSVpbvGytpPK5egA06qSO2W3PlXSFpK2SZkZESxr/h2D7gjbrDEka6q1MAL3qOOy2z5H0hqQHIuJr2x2tFxHDkoaL94huigTQu46G3mxP03jQX42IN4vFh2zPKtpnSRqrp0QAVZiyZ/d4F/6ipD0RsXpC03pJKyU9Wdy/U0uFOKVdeumlbduOHDlSuu6OHTuqLie1Tnbjr5L0e0k7bR//9B/VeMhft32npP2SbqunRABVmDLsEbFFUrsD9OuqLQdAXbhcFkiCsANJEHYgCcIOJEHYgST4iisas3///qZLSIWeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJwdjdm+fXvTJaRCzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJTBl227Ntb7a9x/Zu2/cXy5+w/aXtHcVtaf3lAuhWJz9ecVTSQxGx3fa5krbZ3li0rYmIVfWVB6AqnczP3pLUKh5/Y3uPpAvrLgxAtU7qmN32XElXSNpaLLrP9se2X7I9o806Q7ZHbI/0VCmAnnQcdtvnSHpD0gMR8bWkZyRdImm+xnv+pyZbLyKGI2JhRCysoF4AXeoo7LanaTzor0bEm5IUEYci4lhE/CDpeUmL6isTQK86ORtvSS9K2hMRqycsnzXhZbdI2lV9eQCq0snZ+Ksk/V7STts7imWPSlphe76kkDQq6e5aKsQprdVqddWG6nVyNn6LJE/StKH6cgDUhSvogCQIO5AEYQeSIOxAEoQdSIKwA0k4Ivq3Mbt/GwOSiojJhsrp2YEsCDuQBGEHkiDsQBKEHUiCsANJEHYgiU6+z16lw5L+M+H5+cWyQTSotQ1qXRK1davK2ua0a+jrRTU/2bg9Mqi/TTeotQ1qXRK1datftbEbDyRB2IEkmg77cMPbLzOotQ1qXRK1dasvtTV6zA6gf5ru2QH0CWEHkmgk7LZvtL3X9me2H2mihnZsj9reWUxD3ej8dMUcemO2d01Ydp7tjbb3FfeTzrHXUG0DMY13yTTjjX52TU9/3vdjdttnSPpU0vWSDkj6SNKKiPikr4W0YXtU0sKIaPwCDNuLJR2R9NeIuLxY9hdJX0XEk8U/yhkR8acBqe0JSUeansa7mK1o1sRpxiUtl/QHNfjZldT1O/Xhc2uiZ18k6bOI+Dwivpe0TtKyBuoYeBHxgaSvTli8TNLa4vFajf+x9F2b2gZCRLQiYnvx+BtJx6cZb/SzK6mrL5oI+4WSvpjw/IAGa773kPSe7W22h5ouZhIzI6Iljf/xSLqg4XpONOU03v10wjTjA/PZdTP9ea+aCPtkv481SON/V0XEAklLJN1b7K6iMx1N490vk0wzPhC6nf68V02E/YCk2ROeXyTpYAN1TCoiDhb3Y5Le0uBNRX3o+Ay6xf1Yw/X83yBN4z3ZNOMagM+uyenPmwj7R5Lm2b7Y9lmSbpe0voE6fsL22cWJE9k+W9INGrypqNdLWlk8XinpnQZr+ZFBmca73TTjaviza3z684jo+03SUo2fkf+3pD83UUObun4l6V/FbXfTtUl6TeO7df/V+B7RnZJ+LmmTpH3F/XkDVNvfJO2U9LHGgzWrodqu1vih4ceSdhS3pU1/diV19eVz43JZIAmuoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJP4HJVnB+kVXMCUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"filename\"]=test[\"filename\"].apply(lambda x : \"Images/test/\"+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/test/49000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/test/49001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/test/49002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/test/49003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/test/49004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename\n",
       "0  Images/test/49000.png\n",
       "1  Images/test/49001.png\n",
       "2  Images/test/49002.png\n",
       "3  Images/test/49003.png\n",
       "4  Images/test/49004.png"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "size=28,28\n",
    "t=[]\n",
    "#from PIL import Image\n",
    "import numpy\n",
    "for i in test[\"filename\"]:\n",
    "    im = cv2.imread(i)\n",
    "    im= cv2.resize(im,size)\n",
    "    np_i = numpy.array(im)\n",
    "    np_i=np_i/255\n",
    "    t.append(np_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 28, 28, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolutional_model(classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(2,2),strides=(1,1),activation='relu',input_shape=(28,28,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=64,kernel_size=(2,2),strides=(1,1),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "    model.add(Dropout(0.25))#to prevent neural network from overfitting\n",
    "    \n",
    "    model.add(Conv2D(filters=128,kernel_size=(2,2),strides=(1,1),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=256,kernel_size=(2,2),strides=(1,1),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(classes,activation='softmax'))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sreekar chidurala\\Anaconda3\\envs\\sreekarr\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\sreekar chidurala\\Anaconda3\\envs\\sreekarr\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 32)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 128)       32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3211520   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,526,122\n",
      "Trainable params: 3,523,626\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classes=10\n",
    "model = create_convolutional_model(classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sreekar chidurala\\Anaconda3\\envs\\sreekarr\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      " - 111s - loss: 0.1837 - acc: 0.9422\n",
      "Epoch 2/15\n",
      " - 82s - loss: 0.0751 - acc: 0.9765\n",
      "Epoch 3/15\n",
      " - 82s - loss: 0.0588 - acc: 0.9811\n",
      "Epoch 4/15\n",
      " - 82s - loss: 0.0480 - acc: 0.9850\n",
      "Epoch 5/15\n",
      " - 82s - loss: 0.0435 - acc: 0.9862\n",
      "Epoch 6/15\n",
      " - 82s - loss: 0.0384 - acc: 0.9881\n",
      "Epoch 7/15\n",
      " - 82s - loss: 0.0359 - acc: 0.9889\n",
      "Epoch 8/15\n",
      " - 82s - loss: 0.0335 - acc: 0.9896\n",
      "Epoch 9/15\n",
      " - 83s - loss: 0.0303 - acc: 0.9904\n",
      "Epoch 10/15\n",
      " - 83s - loss: 0.0300 - acc: 0.9901\n",
      "Epoch 11/15\n",
      " - 83s - loss: 0.0291 - acc: 0.9910\n",
      "Epoch 12/15\n",
      " - 83s - loss: 0.0238 - acc: 0.9924\n",
      "Epoch 13/15\n",
      " - 83s - loss: 0.0250 - acc: 0.9920\n",
      "Epoch 14/15\n",
      " - 83s - loss: 0.0232 - acc: 0.9928\n",
      "Epoch 15/15\n",
      " - 83s - loss: 0.0218 - acc: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x229c5611710>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model.fit(images,labels,batch_size=105,epochs=15,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"label\"]=predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49002.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49003.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49004.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename  label\n",
       "0  49000.png      4\n",
       "1  49001.png      0\n",
       "2  49002.png      9\n",
       "3  49003.png      7\n",
       "4  49004.png      9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"mysubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
